{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "226e3fdb",
   "metadata": {},
   "source": [
    "# Task 3: The impact of dimensionality reduction in classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d42d9bd3",
   "metadata": {},
   "source": [
    "The [20newsgroup](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_20newsgroups_vectorized.html) dataset is a high-dimensional text dataset of scikit-learn, used primarily in classification problems. It includes 18846 news articles from 20 categories. The number of features is 130107, a number that may easily trigger the curse of dimensionality for many machine learning algorithms.\n",
    "\n",
    "Apply PCA for various sizes of the input space (e.g. 50, 100, 500, 1000, 10000, and so on). Compare the performance of LogisticRegression, Random Forest Classifier and Multilayer Perceptron on both the reduced, and original dimensional spaces.\n",
    "\n",
    "* Hint 1: Fetch the dataset in [vectorized format](sklearn.datasets.fetch_20newsgroups_vectorized) and convert it by using the [TfidfTransfomer](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfTransformer.html).\n",
    "* Hint 2: In the vast majority of cases, the vectorized text datasets are stored in sparse vectors (namely, most of their components are zero). PCA will not work with such datasets. Use scikit-learn's [TruncatedSVD](https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.TruncatedSVD.html) instead. TruncatedSVD is similar to PCA, however, it  does not center the data before computing the singular value decomposition. This means it can work with sparse matrices efficiently.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "332f680f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.datasets import fetch_20newsgroups_vectorized\n",
    "from sklearn.decomposition import TruncatedSVD as TSVD\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "36e66776",
   "metadata": {},
   "outputs": [],
   "source": [
    "def truncated(components):\n",
    "    tsvd = TSVD(n_components=components, random_state=0)\n",
    "    return tsvd.fit_transform(X_train_tf), tsvd.transform(X_test_tf)\n",
    "    \n",
    "def LogReg(log_reg,Xtrain,Xtest,Ytrain,Ytest):\n",
    "    log_reg.fit(Xtrain, Ytrain)\n",
    "    lr_pred = log_reg.predict(Xtest)\n",
    "    return accuracy_score(Ytest, lr_pred)\n",
    "\n",
    "def RandFor(rf,Xtrain,Xtest,Ytrain,Ytest):  \n",
    "    rf.fit(Xtrain, Ytrain)\n",
    "    rf_pred = rf.predict(Xtest)\n",
    "    return accuracy_score(Ytest, rf_pred)  \n",
    "\n",
    "def MLP_clas(mlp,Xtrain,Xtest,Ytrain,Ytest):\n",
    "    mlp.fit(Xtrain, Ytrain)\n",
    "    mlp_pred = mlp.predict(Xtest)\n",
    "    return accuracy_score(Ytest, mlp_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02aa65be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data fetched successfully.\n",
      "Data transformed successfully.\n",
      "Data truncated successfully.\n"
     ]
    }
   ],
   "source": [
    "initial_dataset=fetch_20newsgroups_vectorized\n",
    "print(\"Data fetched successfully.\")\n",
    "\n",
    "X_train = initial_dataset(subset='train').data\n",
    "Y_train = initial_dataset(subset='train').target\n",
    "X_test = initial_dataset(subset='test').data\n",
    "Y_test = initial_dataset(subset='test').target\n",
    "\n",
    "\n",
    "tfidf = TfidfTransformer()\n",
    "X_train_tf=tfidf.fit_transform(X_train)\n",
    "X_test_tf=tfidf.transform(X_test)\n",
    "print(\"Data transformed successfully.\")\n",
    "\n",
    "\n",
    "X_train_tf_50, X_test_tf_50 = truncated(50)\n",
    "X_train_tf_100, X_test_tf_100 = truncated(100)\n",
    "X_train_tf_500, X_test_tf_500 = truncated(500)\n",
    "X_train_tf_1000, X_test_tf_1000 = truncated(1000)\n",
    "print(\"Data truncated successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a289af7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begining Logistic Regression models testing...\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "print(\"Begining Logistic Regression models testing...\")\n",
    "log_reg = LogisticRegression()\n",
    "accuracy_initial_lr = LogReg(log_reg,X_train_tf,X_test_tf,Y_train,Y_test)\n",
    "accuracy_lr_50 = LogReg(log_reg,X_train_tf_50, X_test_tf_50 ,Y_train,Y_test)\n",
    "accuracy_lr_100 = LogReg(log_reg,X_train_tf_100, X_test_tf_100 ,Y_train,Y_test)\n",
    "accuracy_lr_500 = LogReg(log_reg,X_train_tf_500, X_test_tf_500 ,Y_train,Y_test)\n",
    "accuracy_lr_1000 = LogReg(log_reg,X_train_tf_1000, X_test_tf_1000 ,Y_train,Y_test)\n",
    "print (\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a99d2fa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6453797132235793 ( number of estimators: 100 )\n",
      "Accuracy: 0.6590546999468933 ( number of estimators: 200 )\n",
      "Accuracy: 0.6598513011152416 ( number of estimators: 300 )\n",
      "Accuracy: 0.6633032395114179 ( number of estimators: 400 )\n",
      "Accuracy: 0.6642326075411578 ( number of estimators: 500 )\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing to find best parameters for Random Forest(50 features per entry)\n",
    "estimators=[100,200,300,400,500]\n",
    "final_estimator=100\n",
    "temp=0\n",
    "for estimator in estimators:\n",
    "    rf = RandomForestClassifier(n_estimators=estimator)\n",
    "    accuracy_rf_50 = RandFor(rf, X_train_tf_50, X_test_tf_50 ,Y_train,Y_test)\n",
    "    print(\"Accuracy:\",accuracy_rf_50, \"( number of estimators:\",estimator,\")\")\n",
    "    if accuracy_rf_50 > temp:\n",
    "        final_estimator=estimator\n",
    "        temp = accuracy_rf_50\n",
    "\n",
    "final_estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9d21ce92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begining Random Forest models testing...\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "# Random Forest \n",
    "print(\"Begining Random Forest models testing...\")\n",
    "rf = RandomForestClassifier(n_estimators=final_estimator)\n",
    "\n",
    "accuracy_initial_rf = RandFor(rf, X_train_tf,X_test_tf,Y_train,Y_test)\n",
    "accuracy_rf_50 = RandFor(rf, X_train_tf_50, X_test_tf_50 ,Y_train,Y_test)\n",
    "accuracy_rf_100 = RandFor(rf, X_train_tf_100, X_test_tf_100 ,Y_train,Y_test)\n",
    "accuracy_rf_500 = RandFor(rf, X_train_tf_500, X_test_tf_500 ,Y_train,Y_test)\n",
    "accuracy_rf_1000 = RandFor(rf, X_train_tf_1000, X_test_tf_1000 ,Y_train,Y_test)\n",
    "accuracy_rf_50\n",
    "print (\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f086ba21",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\theof\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7110993096123208 (layers: 50 , learning_rate: 0.001 )\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\theof\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7150823154540626 (layers: 100 , learning_rate: 0.001 )\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\theof\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7247742963356346 (layers: 200 , learning_rate: 0.001 )\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\theof\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7181359532660648 (layers: 300 , learning_rate: 0.001 )\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\theof\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.717870419543282 (layers: 400 , learning_rate: 0.001 )\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\theof\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7132235793945831 (layers: 50 , learning_rate: 0.002 )\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\theof\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7099044078597982 (layers: 100 , learning_rate: 0.002 )\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\theof\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7140201805629315 (layers: 200 , learning_rate: 0.002 )\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\theof\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7164099840679766 (layers: 300 , learning_rate: 0.002 )\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\theof\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7168082846521509 (layers: 400 , learning_rate: 0.002 )\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\theof\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6974243228890069 (layers: 50 , learning_rate: 0.01 )\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\theof\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6783058948486458 (layers: 100 , learning_rate: 0.01 )\n",
      "Accuracy: 0.6804301646309081 (layers: 200 , learning_rate: 0.01 )\n",
      "Accuracy: 0.6955655868295274 (layers: 300 , learning_rate: 0.01 )\n",
      "Accuracy: 0.6946362187997875 (layers: 400 , learning_rate: 0.01 )\n",
      "Accuracy: 0.6795007966011684 (layers: 50 , learning_rate: 0.1 )\n",
      "Accuracy: 0.6593202336696761 (layers: 100 , learning_rate: 0.1 )\n",
      "Accuracy: 0.6625066383430696 (layers: 200 , learning_rate: 0.1 )\n",
      "Accuracy: 0.661975570897504 (layers: 300 , learning_rate: 0.1 )\n",
      "Accuracy: 0.6575942644715879 (layers: 400 , learning_rate: 0.1 )\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.001, 200]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing to find best parameters for MLP classifier (50 features per entry)\n",
    "rates = [0.001,0.002,0.01,0.1]\n",
    "layers = [50,100,200,300,400]\n",
    "final_parameters = [0,0]\n",
    "temp = 0\n",
    "for rate in rates:\n",
    "    for layer in layers:\n",
    "      mlp = MLPClassifier(hidden_layer_sizes=(layer,),max_iter=300, learning_rate_init=rate)\n",
    "      accuracy_mlp_50 = MLP_clas(mlp,X_train_tf_50, X_test_tf_50 ,Y_train,Y_test)\n",
    "      print(\"Accuracy:\", accuracy_mlp_50,\"(layers:\",layer,\", learning_rate:\",rate,\")\")\n",
    "      if accuracy_mlp_50 > temp:\n",
    "        final_parameters = [rate , layer]\n",
    "        temp = accuracy_mlp_50\n",
    "final_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b7411e28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.001, 200]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4623ceca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begining MLP models testing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\theof\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\theof\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "# MLP\n",
    "print(\"Begining MLP models testing...\")\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(final_parameters[1],), max_iter= 300, learning_rate_init=final_parameters[0])\n",
    "accuracy_initial_mlp = MLP_clas(mlp,X_train_tf,X_test_tf,Y_train,Y_test)\n",
    "accuracy_mlp_50 = MLP_clas(mlp,X_train_tf_50, X_test_tf_50 ,Y_train,Y_test)\n",
    "accuracy_mlp_100 = MLP_clas(mlp,X_train_tf_100, X_test_tf_100 ,Y_train,Y_test)\n",
    "accuracy_mlp_500 = MLP_clas(mlp,X_train_tf_500, X_test_tf_500 ,Y_train,Y_test)\n",
    "accuracy_mlp_1000 = MLP_clas(mlp,X_train_tf_1000, X_test_tf_1000 ,Y_train,Y_test)\n",
    "print (\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "637c3b77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features for best score - Logistic Regression is 50 with accuracy equal to 0.8274030801911842\n",
      "Number of features for best score - Random Forrest is 50 with accuracy equal to 0.7879713223579394\n",
      "Number of features for best score - MultiLayer Perceptron is 50 with accuracy equal to 0.846388741370154\n"
     ]
    }
   ],
   "source": [
    "#Print number of features for best accuracy score in every model\n",
    "lr_scores={\"50\":accuracy_initial_lr,\"100\":accuracy_lr_100,\"500\":accuracy_lr_500,\"1000\":accuracy_lr_1000}\n",
    "rf_scores={\"50\":accuracy_initial_rf,\"100\":accuracy_rf_100,\"500\":accuracy_rf_500,\"1000\":accuracy_rf_1000}\n",
    "mlp_scores={\"50\":accuracy_initial_mlp,\"100\":accuracy_mlp_100,\"500\":accuracy_mlp_500,\"1000\":accuracy_mlp_1000}\n",
    "\n",
    "best_lr= max(lr_scores, key=lr_scores.get)\n",
    "best_rf = max(rf_scores, key=rf_scores.get)\n",
    "best_mlp = max(mlp_scores, key=mlp_scores.get)\n",
    "\n",
    "print(\"Number of features for best score - Logistic Regression is\", best_lr,\"with accuracy equal to\", lr_scores[best_lr])\n",
    "print(\"Number of features for best score - Random Forrest is\", best_rf,\"with accuracy equal to\", rf_scores[best_rf])\n",
    "print(\"Number of features for best score - MultiLayer Perceptron is\", best_mlp,\"with accuracy equal to\", mlp_scores[best_mlp])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d0c121a",
   "metadata": {},
   "source": [
    "# Deliverables\n",
    "\n",
    "You will provide your solutions in this notebook. Just place your code below each task. You must also provide comments on the obtained results.\n",
    "\n",
    "In the sequel:\n",
    "1. Rename the notebook (i.e. the `.ipynb` file) by giving it your last and first names.\n",
    "2. Go to _File &raquo; Download as &raquo; HTML (.html)_. Download the generated HTML file.\n",
    "3. Compress both the `.ipynb` and `.html` files into a single `.zip` file. **Ensure that the `.zip` archive includes only these two files.**\n",
    "4. Rename the `.zip` file and give it your last and first names. Finally, upload it to the e-learning platform.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
